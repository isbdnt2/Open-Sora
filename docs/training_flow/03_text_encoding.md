# 03. 文本编码 (Text Encoding)

## 流程图

```
┌─────────────────────────────────────────────────────────────────────────────────────┐
│                              文本编码流程                                            │
├─────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │                          1. T5 编码器                                        │   │
│   ├─────────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                             │   │
│   │   文本输入                              T5 嵌入                              │   │
│   │   prompt: List[str]      T5 Encoder     txt [B, L, 4096]                    │   │
│   │   ["A cat...", ...]     ──────────►    [16, 512, 4096]                      │   │
│   │                                                                             │   │
│   │   ┌─────────────────────────────────────────────────────────────────────┐   │   │
│   │   │                      T5-XXL Encoder                                 │   │   │
│   │   │                                                                     │   │   │
│   │   │   ┌─────────┐     ┌─────────┐     ┌─────────┐                       │   │   │
│   │   │   │Tokenizer│ ──► │ Embed   │ ──► │Encoder  │                       │   │   │
│   │   │   │         │     │         │     │ ×24层   │                       │   │   │
│   │   │   └─────────┘     └─────────┘     └─────────┘                       │   │   │
│   │   │                                        │                            │   │   │
│   │   │                                        ▼                            │   │   │
│   │   │                              ┌─────────────────┐                    │   │   │
│   │   │                              │  last_hidden    │                    │   │   │
│   │   │                              │  [B, L, 4096]   │                    │   │   │
│   │   │                              └─────────────────┘                    │   │   │
│   │   │                                                                     │   │   │
│   │   │   特点:                                                             │   │   │
│   │   │   - 最大长度: 512 tokens (可配置)                                   │   │   │
│   │   │   - 隐藏维度: 4096                                                  │   │   │
│   │   │   - 参数量: ~4.8B                                                   │   │   │
│   │   │   - 用途: 细粒度语义描述                                            │   │   │
│   │   │                                                                     │   │   │
│   │   └─────────────────────────────────────────────────────────────────────┘   │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │                          2. CLIP 编码器                                      │   │
│   ├─────────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                             │   │
│   │   文本输入                              CLIP 嵌入                           │   │
│   │   prompt: List[str]     CLIP Encoder    y_vec [B, 768]                     │   │
│   │   ["A cat...", ...]    ──────────►     [16, 768]                           │   │
│   │                                                                             │   │
│   │   ┌─────────────────────────────────────────────────────────────────────┐   │   │
│   │   │                      CLIP Text Encoder                              │   │   │
│   │   │                                                                     │   │   │
│   │   │   ┌─────────┐     ┌─────────┐     ┌─────────┐                       │   │   │
│   │   │   │Tokenizer│ ──► │ Embed   │ ──► │Transformer│                     │   │   │
│   │   │   │ (77 max)│     │         │     │  ×12层  │                       │   │   │
│   │   │   └─────────┘     └─────────┘     └─────────┘                       │   │   │
│   │   │                                        │                            │   │   │
│   │   │                                        ▼                            │   │   │
│   │   │                              ┌─────────────────┐                    │   │   │
│   │   │                              │  pooled_output  │                    │   │   │
│   │   │                              │  [B, 768]       │                    │   │   │
│   │   │                              │  (EOS token)    │                    │   │   │
│   │   │                              └─────────────────┘                    │   │   │
│   │   │                                                                     │   │   │
│   │   │   特点:                                                             │   │   │
│   │   │   - 最大长度: 77 tokens                                             │   │   │
│   │   │   - 隐藏维度: 768                                                   │   │   │
│   │   │   - 参数量: ~340M                                                   │   │   │
│   │   │   - 用途: 全局语义向量 (用于 timestep 调制)                         │   │   │
│   │   │                                                                     │   │   │
│   │   └─────────────────────────────────────────────────────────────────────┘   │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │                          3. Dropout (CFG 训练)                               │   │
│   ├─────────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                             │   │
│   │   训练时随机将文本条件替换为 null 向量:                                     │   │
│   │                                                                             │   │
│   │   ┌─────────────────────────────────────────────────────────────────────┐   │   │
│   │   │   dropout_ratio = {                                                 │   │   │
│   │   │       "t5": 0.3,    # 30% 概率替换 T5 为 null                       │   │   │
│   │   │       "clip": 0.3,  # 30% 概率替换 CLIP 为 null                     │   │   │
│   │   │   }                                                                 │   │   │
│   │   └─────────────────────────────────────────────────────────────────────┘   │   │
│   │                                                                             │   │
│   │   Dropout 逻辑:                                                             │   │
│   │   ┌─────────────────────────────────────────────────────────────────────┐   │   │
│   │   │   for each sample in batch:                                         │   │   │
│   │   │       if random() < 0.3:                                            │   │   │
│   │   │           txt[i] = null_txt   # T5 null embedding                   │   │   │
│   │   │       if random() < 0.3:                                            │   │   │
│   │   │           y_vec[i] = null_vec # CLIP null embedding                 │   │   │
│   │   └─────────────────────────────────────────────────────────────────────┘   │   │
│   │                                                                             │   │
│   │   目的:                                                                     │   │
│   │   - 训练模型同时学习有条件和无条件生成                                      │   │
│   │   - 推理时使用 CFG: output = uncond + scale × (cond - uncond)              │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │                          4. Position IDs 准备                                │   │
│   ├─────────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                             │   │
│   │   为 3D RoPE 准备位置索引:                                                  │   │
│   │                                                                             │   │
│   │   img_ids [B, N, 3]:  视频 tokens 的 (T, H, W) 坐标                         │   │
│   │   txt_ids [B, L, 3]:  文本 tokens 的位置 (全为 0)                           │   │
│   │                                                                             │   │
│   │   img_ids 示例 (5帧, 16×16):                                                │   │
│   │   ┌─────────────────────────────────────────────────────────────────────┐   │   │
│   │   │   token_0:  [0, 0, 0]    # t=0, h=0, w=0                            │   │   │
│   │   │   token_1:  [0, 0, 1]    # t=0, h=0, w=1                            │   │   │
│   │   │   ...                                                               │   │   │
│   │   │   token_255: [0, 15, 15] # t=0, h=15, w=15                          │   │   │
│   │   │   token_256: [1, 0, 0]   # t=1, h=0, w=0                            │   │   │
│   │   │   ...                                                               │   │   │
│   │   │   token_1279: [4, 15, 15] # t=4, h=15, w=15                         │   │   │
│   │   └─────────────────────────────────────────────────────────────────────┘   │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
└─────────────────────────────────────────────────────────────────────────────────────┘
```

## 输入/输出规格

### T5 编码

| 输入 | 类型 | 描述 |
|-----|------|------|
| `prompt` | `List[str]` | B 个文本描述 |

| 输出 | 形状 | 描述 |
|-----|------|------|
| `txt` | `[B, L, 4096]` | T5 隐藏状态 |

### CLIP 编码

| 输入 | 类型 | 描述 |
|-----|------|------|
| `prompt` | `List[str]` | B 个文本描述 |

| 输出 | 形状 | 描述 |
|-----|------|------|
| `y_vec` | `[B, 768]` | CLIP pooled 输出 |

### 完整输出

| 输出 | 形状 | 描述 |
|-----|------|------|
| `txt` | `[B, L, 4096]` | T5 嵌入 (可能 dropout) |
| `txt_ids` | `[B, L, 3]` | 文本位置索引 |
| `y_vec` | `[B, 768]` | CLIP 向量 (可能 dropout) |
| `img_ids` | `[B, N, 3]` | 视频位置索引 |

## 关键代码

### prepare 函数 (完整文本编码)

```python
# 位置: opensora/utils/sampling.py

def prepare(
    model_t5,
    model_clip,
    x_0: Tensor,                    # [B, C, T, H, W] VAE latent
    prompt: list[str],              # B 个文本
    seq_align: int = 1,             # 序列对齐 (用于序列并行)
    patch_size: int = 2,
) -> dict:
    """编码文本并准备位置索引"""
    
    # T5 编码
    txt = model_t5(prompt)  # [B, L, 4096]
    
    # CLIP 编码
    y_vec = model_clip(prompt)  # [B, 768]
    
    # 序列对齐 padding (用于序列并行)
    if seq_align > 1:
        txt = pad_to_align(txt, seq_align)
    
    # 准备位置 IDs
    img_ids = prepare_image_ids(x_0, patch_size)  # [B, N, 3]
    txt_ids = torch.zeros(txt.shape[0], txt.shape[1], 3, device=txt.device)  # [B, L, 3]
    
    return {
        "txt": txt,
        "txt_ids": txt_ids,
        "y_vec": y_vec,
        "img_ids": img_ids,
    }
```

### prepare_ids 函数 (使用预缓存文本)

```python
# 位置: opensora/utils/sampling.py

def prepare_ids(
    x_0: Tensor,              # [B, C, T, H, W]
    t5_embedding: Tensor,     # [B, L, 4096] 预计算
    clip_embedding: Tensor,   # [B, 768] 预计算
    seq_align: int = 1,
    patch_size: int = 2,
) -> dict:
    """使用预缓存的文本嵌入准备输入"""
    
    txt = t5_embedding
    y_vec = clip_embedding
    
    # 序列对齐
    if seq_align > 1:
        txt = pad_to_align(txt, seq_align)
    
    img_ids = prepare_image_ids(x_0, patch_size)
    txt_ids = torch.zeros(txt.shape[0], txt.shape[1], 3, device=txt.device)
    
    return {
        "txt": txt,
        "txt_ids": txt_ids,
        "y_vec": y_vec,
        "img_ids": img_ids,
    }
```

### 准备位置 IDs

```python
# 位置: opensora/utils/sampling.py

def prepare_image_ids(x: Tensor, patch_size: int = 2) -> Tensor:
    """为视频 tokens 准备 3D 位置索引
    
    Args:
        x: [B, C, T, H, W] VAE latent
        patch_size: patch 大小
    
    Returns:
        [B, N, 3] 位置索引，每个 token 有 (t, h, w) 三个坐标
    """
    B, C, T, H, W = x.shape
    h = H // patch_size  # 16
    w = W // patch_size  # 16
    n = T * h * w        # 1280
    
    # 创建 3D 网格
    t_ids = torch.arange(T, device=x.device)
    h_ids = torch.arange(h, device=x.device)
    w_ids = torch.arange(w, device=x.device)
    
    # meshgrid 展开
    tt, hh, ww = torch.meshgrid(t_ids, h_ids, w_ids, indexing='ij')
    
    # 堆叠成 [N, 3]
    img_ids = torch.stack([tt.flatten(), hh.flatten(), ww.flatten()], dim=-1)
    
    # 扩展 batch 维度 [B, N, 3]
    img_ids = img_ids.unsqueeze(0).expand(B, -1, -1).float()
    
    return img_ids
```

### Dropout 函数

```python
# 位置: opensora/utils/train.py

def dropout_condition(
    prob: float,
    txt: torch.Tensor,      # [B, L, D]
    null_txt: torch.Tensor, # [1, L, D] 或 [B, L, D]
) -> torch.Tensor:
    """
    以 prob 概率将 txt 替换为 null_txt
    """
    if prob == 0:
        return txt
    
    # 为每个 batch 样本生成 dropout mask
    drop_ids = torch.rand(txt.shape[0], device=txt.device) < prob
    drop_ids = drop_ids.view((drop_ids.shape[0],) + (1,) * (txt.ndim - 1))
    # drop_ids: [B, 1, 1] 广播到 [B, L, D]
    
    new_txt = torch.where(drop_ids, null_txt, txt)
    return new_txt
```

## T5 vs CLIP 对比

```
┌─────────────────────────────────────────────────────────────────────────────────────┐
│                              T5 vs CLIP 文本编码器                                   │
├─────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                     │
│   ┌────────────────────────────────┬────────────────────────────────┐               │
│   │            T5-XXL              │           CLIP                 │               │
│   ├────────────────────────────────┼────────────────────────────────┤               │
│   │                                │                                │               │
│   │  输出: 序列嵌入                │  输出: 单一向量                │               │
│   │  [B, L, 4096]                  │  [B, 768]                      │               │
│   │                                │                                │               │
│   │  最大长度: 512                 │  最大长度: 77                  │               │
│   │                                │                                │               │
│   │  参数量: ~4.8B                 │  参数量: ~340M                 │               │
│   │                                │                                │               │
│   │  特点:                         │  特点:                         │               │
│   │  - 保留每个 token 的信息       │  - 压缩为全局语义               │               │
│   │  - 细粒度文本理解              │  - 快速计算                    │               │
│   │  - 支持长文本描述              │  - 图文对齐预训练              │               │
│   │                                │                                │               │
│   │  用途:                         │  用途:                         │               │
│   │  - Cross-attention             │  - Timestep 调制               │               │
│   │  - 与视频 tokens 交互          │  - 全局条件注入                │               │
│   │                                │                                │               │
│   └────────────────────────────────┴────────────────────────────────┘               │
│                                                                                     │
│   在 MMDiT 中的使用方式:                                                            │
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │                                                                             │   │
│   │   T5 嵌入 (txt):                                                            │   │
│   │   ┌───────────────────────────────────────────────────────────────────┐     │   │
│   │   │  txt_in = Linear(4096, 3072)  # 投影到模型维度                   │     │   │
│   │   │  与 img tokens 进行 Joint Attention (DoubleStreamBlock)          │     │   │
│   │   │  或 Concat 后 Self-Attention (SingleStreamBlock)                 │     │   │
│   │   └───────────────────────────────────────────────────────────────────┘     │   │
│   │                                                                             │   │
│   │   CLIP 嵌入 (y_vec):                                                        │   │
│   │   ┌───────────────────────────────────────────────────────────────────┐     │   │
│   │   │  vec_in = MLP(768, 3072)  # 投影到模型维度                       │     │   │
│   │   │  与 timestep 嵌入相加，用于 AdaLN 调制                           │     │   │
│   │   │  cond_vec = time_emb + clip_emb                                  │     │   │
│   │   │  scale, shift, gate = AdaLN(cond_vec)                            │     │   │
│   │   └───────────────────────────────────────────────────────────────────┘     │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
└─────────────────────────────────────────────────────────────────────────────────────┘
```

## Null 向量初始化

```python
# 位置: scripts/diffusion/train.py

# 训练开始前预计算 null 向量
if cfg.get("cached_text", False):
    # 从缓存加载
    null_txt = torch.load("null_t5.pt", map_location=device)
    null_vec = torch.load("null_clip.pt", map_location=device)
else:
    # 实时编码空字符串
    null_txt = model_t5("")  # [1, L, 4096]
    null_vec = model_clip("")  # [1, 768]

# null_txt 和 null_vec 用于 Dropout
```

## 维度变换完整示例

以 batch size 16、T5 最大长度 512 为例：

```
1. 输入
   prompt: ["A cat running...", "Ocean waves...", ...] (16 个字符串)

2. T5 编码
   txt: [16, 512, 4096]
   (B=16, L=512, D=4096)

3. CLIP 编码
   y_vec: [16, 768]
   (B=16, D=768)

4. 位置 IDs (视频 5×16×16)
   img_ids: [16, 1280, 3]
   (B=16, N=1280, 3维坐标)
   
   txt_ids: [16, 512, 3]
   (B=16, L=512, 3维坐标，全为0)

5. Dropout 后 (30% 概率)
   txt: [16, 512, 4096]  # 约 5 个样本被替换为 null_txt
   y_vec: [16, 768]      # 约 5 个样本被替换为 null_vec
   (Dropout 独立应用于 T5 和 CLIP)
```
