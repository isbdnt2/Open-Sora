# 03. 输入准备 (Prepare Inputs)

## 流程图

```
┌─────────────────────────────────────────────────────────────────────────────────────┐
│                               输入准备流程                                           │
├─────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │                          1. Patchify (图像分块)                              │   │
│   ├─────────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                             │   │
│   │   输入噪声 z                           分块后 img                            │   │
│   │   [B, C, T, H, W]                      [B, N, C×patch²]                     │   │
│   │                                                                             │   │
│   │   ┌───┬───┬───┬───┐                   ┌─────────────────────────┐           │   │
│   │   │ 0 │ 1 │ 2 │ 3 │                   │ Token 0: patch(0,0)     │           │   │
│   │   ├───┼───┼───┼───┤    Patchify      │ Token 1: patch(0,1)     │           │   │
│   │   │ 4 │ 5 │ 6 │ 7 │   ─────────►     │ Token 2: patch(1,0)     │           │   │
│   │   ├───┼───┼───┼───┤   patch=2×2      │ Token 3: patch(1,1)     │           │   │
│   │   │ 8 │ 9 │10 │11 │                   │ ...                     │           │   │
│   │   ├───┼───┼───┼───┤                   │ Token N-1: 最后一个patch│           │   │
│   │   │12 │13 │14 │15 │                   └─────────────────────────┘           │   │
│   │   └───┴───┴───┴───┘                                                         │   │
│   │   (H/patch × W/patch)                  N = T × (H/patch) × (W/patch)        │   │
│   │                                                                             │   │
│   │   einops: "b c t (h ph) (w pw) -> b (t h w) (c ph pw)"                      │   │
│   │           ph=pw=patch_size                                                  │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │                          2. 位置 ID 生成                                     │   │
│   ├─────────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                             │   │
│   │   img_ids: 每个 patch 的 (t, h, w) 位置                                     │   │
│   │   [B, N, 3]                                                                 │   │
│   │                                                                             │   │
│   │   ┌─────────────────────────────────────────────────────────────────┐       │   │
│   │   │  Token 0:  [t=0, h=0, w=0]                                      │       │   │
│   │   │  Token 1:  [t=0, h=0, w=1]                                      │       │   │
│   │   │  Token 2:  [t=0, h=1, w=0]                                      │       │   │
│   │   │  ...                                                            │       │   │
│   │   │  Token K:  [t=1, h=0, w=0]  (下一帧开始)                        │       │   │
│   │   │  ...                                                            │       │   │
│   │   └─────────────────────────────────────────────────────────────────┘       │   │
│   │                                                                             │   │
│   │   txt_ids: 文本位置（全零，因为 T5 已有位置编码）                            │   │
│   │   [B, seq_len, 3]   全为 0                                                  │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │                          3. I2V 条件准备（可选）                             │   │
│   ├─────────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                             │   │
│   │   参考图片                 VAE Encode              条件潜在表示              │   │
│   │   [B, 3, H, W]      →     HunyuanVAE      →      ref_latent                 │   │
│   │                                                   [B, 16, 1, H', W']        │   │
│   │                                                                             │   │
│   │   cond_type 决定如何使用参考图:                                             │   │
│   │   ┌───────────────┬──────────────────────────────────────────────┐          │   │
│   │   │ "i2v_head"    │ 参考图作为第一帧                              │          │   │
│   │   │ "i2v_tail"    │ 参考图作为最后一帧                            │          │   │
│   │   │ "i2v_loop"    │ 参考图作为首尾帧（循环视频）                  │          │   │
│   │   │ "t2v"         │ 无参考图，纯文本生成                          │          │   │
│   │   └───────────────┴──────────────────────────────────────────────┘          │   │
│   │                                                                             │   │
│   │   生成 masks 和 masked_ref:                                                 │   │
│   │   ┌──────────────────────────────────────────────────────────────────┐      │   │
│   │   │  masks:      [B, 1, T, H', W']   - 哪些帧是条件帧 (1=条件)      │      │   │
│   │   │  masked_ref: [B, 16, T, H', W']  - 条件帧的潜在表示             │      │   │
│   │   │                                                                  │      │   │
│   │   │  i2v_head 示例 (5帧):                                           │      │   │
│   │   │  masks:      [1, 0, 0, 0, 0]                                    │      │   │
│   │   │  masked_ref: [ref, 0, 0, 0, 0]                                  │      │   │
│   │   └──────────────────────────────────────────────────────────────────┘      │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │                          4. 输出汇总                                         │   │
│   ├─────────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                             │   │
│   │   ┌────────────────────────────────────────────────────────────────────┐    │   │
│   │   │  传入 MMDiT 模型的输入字典:                                        │    │   │
│   │   │                                                                    │    │   │
│   │   │  {                                                                 │    │   │
│   │   │    "img":     [B, N, hidden_size],      # Patchified 噪声          │    │   │
│   │   │    "img_ids": [B, N, 3],                # 图像位置 ID              │    │   │
│   │   │    "txt":     [B, seq_len, hidden_size],# T5 文本嵌入              │    │   │
│   │   │    "txt_ids": [B, seq_len, 3],          # 文本位置 ID (全0)        │    │   │
│   │   │    "y_vec":   [B, hidden_size],         # CLIP 全局向量            │    │   │
│   │   │    "cond":    [B, N, cond_dim],         # I2V 条件 (可选)          │    │   │
│   │   │  }                                                                 │    │   │
│   │   └────────────────────────────────────────────────────────────────────┘    │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
└─────────────────────────────────────────────────────────────────────────────────────┘
```

## 输入/输出规格

### Patchify

| 输入 | 形状 | 描述 |
|-----|------|------|
| `z` | `[B, C, T, H, W]` | 噪声潜在表示 |
| `patch_size` | `int` | Patch 大小（默认 2） |

| 输出 | 形状 | 描述 |
|-----|------|------|
| `img` | `[B, N, C×patch²]` | 分块后的序列 |

其中 `N = T × (H/patch) × (W/patch)`

### 位置 ID

| 输出 | 形状 | 描述 |
|-----|------|------|
| `img_ids` | `[B, N, 3]` | 每个 patch 的 (t, h, w) 坐标 |
| `txt_ids` | `[B, seq_len, 3]` | 文本位置（全零） |

### I2V 条件

| 输出 | 形状 | 描述 |
|-----|------|------|
| `masks` | `[B, 1, T, H', W']` | 条件帧掩码 |
| `masked_ref` | `[B, C, T, H', W']` | 条件帧潜在表示 |
| `cond` | `[B, N, C+1]` | Pack 后的条件（mask + ref） |

## 关键代码

### Patchify 和位置编码

```python
# 位置: opensora/utils/sampling.py - prepare() 函数

def prepare(t5, clip, img, prompt, seq_align=1, patch_size=2):
    bs, c, t, h, w = img.shape
    device, dtype = img.device, img.dtype
    
    # 1. Patchify: 将 5D 张量展平为序列
    img = rearrange(
        img, "b c t (h ph) (w pw) -> b (t h w) (c ph pw)", 
        ph=patch_size, pw=patch_size
    )
    # 输入: [B, 16, 5, 64, 64]
    # 输出: [B, 5*32*32, 16*2*2] = [B, 5120, 64]
    
    # 2. 生成图像位置 ID
    img_ids = torch.zeros(t, h // patch_size, w // patch_size, 3)
    img_ids[..., 0] = img_ids[..., 0] + torch.arange(t)[:, None, None]      # 时间位置
    img_ids[..., 1] = img_ids[..., 1] + torch.arange(h // patch_size)[None, :, None]  # 高度位置
    img_ids[..., 2] = img_ids[..., 2] + torch.arange(w // patch_size)[None, None, :]  # 宽度位置
    img_ids = repeat(img_ids, "t h w c -> b (t h w) c", b=bs)
    # 输出: [B, 5120, 3]
    
    # 3. 文本编码
    txt = t5(prompt, added_tokens=img_ids.shape[1], seq_align=seq_align)
    txt_ids = torch.zeros(bs, txt.shape[1], 3)  # 文本位置全0
    vec = clip(prompt)
    
    return {
        "img": img,
        "img_ids": img_ids.to(device, dtype),
        "txt": txt.to(device, dtype),
        "txt_ids": txt_ids.to(device, dtype),
        "y_vec": vec.to(device, dtype),
    }
```

### Pack 函数

```python
# 位置: opensora/utils/sampling.py

def pack(x: Tensor, patch_size: int = 2) -> Tensor:
    """将 5D 张量 pack 成 3D 序列"""
    return rearrange(
        x, "b c t (h ph) (w pw) -> b (t h w) (c ph pw)", 
        ph=patch_size, pw=patch_size
    )

def unpack(x: Tensor, height: int, width: int, num_frames: int, patch_size: int = 2) -> Tensor:
    """将 3D 序列 unpack 回 5D 张量"""
    D = int(os.environ.get("AE_SPATIAL_COMPRESSION", 16))
    return rearrange(
        x,
        "b (t h w) (c ph pw) -> b c t (h ph) (w pw)",
        h=math.ceil(height / D),
        w=math.ceil(width / D),
        t=num_frames,
        ph=patch_size,
        pw=patch_size,
    )
```

### I2V 条件准备

```python
# 位置: opensora/utils/inference.py

def prepare_inference_condition(z, cond_type, ref_list, causal=True):
    """准备 I2V 推理的条件"""
    B, C, T, H, W = z.shape
    
    # 初始化为全零
    masks = torch.zeros(B, 1, T, H, W, device=z.device, dtype=z.dtype)
    masked_ref = torch.zeros_like(z)
    
    for i, ref in enumerate(ref_list):
        if ref is None:
            continue
            
        if cond_type == "i2v_head":
            # 参考图作为第一帧
            masks[i, :, 0] = 1.0
            masked_ref[i, :, 0] = ref[0]  # ref shape: [1, C, H, W]
            
        elif cond_type == "i2v_tail":
            # 参考图作为最后一帧
            masks[i, :, -1] = 1.0
            masked_ref[i, :, -1] = ref[0]
            
        elif cond_type == "i2v_loop":
            # 参考图作为首尾帧
            masks[i, :, 0] = 1.0
            masks[i, :, -1] = 1.0
            masked_ref[i, :, 0] = ref[0]
            masked_ref[i, :, -1] = ref[1] if len(ref) > 1 else ref[0]
    
    return masks, masked_ref
```

## 维度变换示例

以 256×256 分辨率、17 帧视频为例：

```
1. 初始噪声
   z: [1, 16, 5, 64, 64]
   (B=1, C=16, T'=5, H'=64, W'=64)
   注: H'=64 因为 patch_size=2 预留

2. Patchify
   img: [1, 5120, 64]
   (B=1, N=5×32×32=5120, C×patch²=16×4=64)

3. 位置 ID
   img_ids: [1, 5120, 3]
   每个 token 对应 (t, h, w) 坐标
   
   示例:
   token 0:    [0, 0, 0]   # 帧0, 行0, 列0
   token 1:    [0, 0, 1]   # 帧0, 行0, 列1
   token 32:   [0, 1, 0]   # 帧0, 行1, 列0
   token 1024: [1, 0, 0]   # 帧1, 行0, 列0

4. 线性投影后 (在模型中)
   img_in: nn.Linear(64, hidden_size=768)
   img: [1, 5120, 768]

5. 与文本拼接
   txt: [1, 512, 768]
   combined_ids: [1, 512+5120, 3] = [1, 5632, 3]
   
   用于 RoPE 位置编码
```

## RoPE 位置编码

```
┌─────────────────────────────────────────────────────────────────────────────────────┐
│                              3D RoPE 位置编码                                        │
├─────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                     │
│   配置: axes_dim = [16, 56, 56]  (总和 = 128 = head_dim)                            │
│                                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────────────┐   │
│   │   每个 head 的 128 维 attention 向量:                                        │   │
│   │                                                                             │   │
│   │   ┌──────────────┬────────────────────────┬────────────────────────┐        │   │
│   │   │  时间位置     │      高度位置           │      宽度位置           │        │   │
│   │   │  (16 dim)    │      (56 dim)          │      (56 dim)          │        │   │
│   │   │              │                        │                        │        │   │
│   │   │  RoPE(t)     │      RoPE(h)           │      RoPE(w)           │        │   │
│   │   └──────────────┴────────────────────────┴────────────────────────┘        │   │
│   │                                                                             │   │
│   │   RoPE 使 attention 具有相对位置感知能力:                                    │   │
│   │   - 相邻帧的 token 更容易 attend                                            │   │
│   │   - 同一帧内相邻位置的 token 更容易 attend                                   │   │
│   │   - 位置信息被编码到 Q 和 K 的旋转中                                         │   │
│   │                                                                             │   │
│   └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
│   文本 token 的位置 ID 全为 0:                                                      │
│   - T5 已经有自己的位置编码                                                        │
│   - 文本被视为"位置无关"的全局条件                                                 │
│   - 通过 Joint Attention 与图像交互                                                │
│                                                                                     │
└─────────────────────────────────────────────────────────────────────────────────────┘
```
